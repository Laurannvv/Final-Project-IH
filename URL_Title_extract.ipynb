{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import tools\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import lxml\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define function to get link of the laws\n",
    "\n",
    "# def get_laws(link)\n",
    "# request the html content\n",
    "#html = requests.get(link).content\n",
    "# extract the URL of each laws in html text with beautiful soup and findall\n",
    "#soup = BeautifulSoup(html, \"lxml\")\n",
    "#tags = [URL localtion]\n",
    "#text = [element.text for element in soup.find_all(tags)]\n",
    "# extract the title each laws in html text with beautiful soup and findall\n",
    "#tags = ['h2']\n",
    "#text = [element.text for element in soup.find_all(tags)]\n",
    "#Create DF with the URL and title\n",
    "#return list of URL\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://eur-lex.europa.eu/search.html?SUBDOM_INIT=ALL_ALL&DB_TYPE_OF_ACT=regulation&DTS_SUBDOM=ALL_ALL&typeOfActStatus=REGULATION&DTS_DOM=ALL&type=advanced&excConsLeg=true&qid=1607094868246'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define function\n",
    "\n",
    "def get_laws_p1_only(url):\n",
    "    html = requests.get(url).content\n",
    "    soup = BeautifulSoup(html, \"lxml\")\n",
    "    urls = list(soup.find_all('h2'))\n",
    "    txt1=[]\n",
    "    titles=[]\n",
    "    txt2=[]\n",
    "    for url in urls:\n",
    "        txt1.append(re.findall('https://?[\\w/\\-?=%.]+\\.[\\w/\\-?=%.:\\d]+', str(url)))\n",
    "    for title in urls:\n",
    "        titles.append(re.findall('>\\w+.+<',str(title)))\n",
    "    for line in titles:\n",
    "        for el in line:\n",
    "            txt2.append(re.sub('[><]|/a','',el))\n",
    "    document_list= pd.DataFrame({\n",
    "        'Titles': txt2[1:],\n",
    "        'URL': txt1[1:]})\n",
    "    return document_list\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define function - modification to include the function in the final extraction code\n",
    "def get_laws_p1(url):\n",
    "    titles=[]\n",
    "    html = requests.get(url).content\n",
    "    soup = BeautifulSoup(html, \"lxml\")\n",
    "    urls = list(soup.find_all('h2'))\n",
    "    for url in urls:\n",
    "        txt1.append(re.findall('https://?[\\w/\\-?=%.]+\\.[\\w/\\-?=%.:\\d]+', str(url)))\n",
    "    for title in urls:\n",
    "        titles.append(re.findall('>\\w+.+<',str(title)))\n",
    "for line in titles:\n",
    "    for el in line:\n",
    "        txt_title.append(re.sub('[><]|/a','',el))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a code that manage to extract data in the next pages.\n",
    "\n",
    "# define the url with numpy array\n",
    "\n",
    "#pages = np.arange(1,10)\n",
    "#pages_add =[]\n",
    "#for i in pages:\n",
    "#pages_add.append\n",
    "\n",
    "# for loop the url\n",
    "\n",
    "#for i in pages_add:\n",
    "#requests.get(i)\n",
    "# => get Html content\n",
    "# Insert get_law_p1 as page 1 is diffÃ©rent than the other pages\n",
    "# Insert the previsouly defined adapted to next pages extraction\n",
    "# use the previsouly define function to extract laws of each pages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extraction code\n",
    "\n",
    "txt1=[]\n",
    "titles=[]\n",
    "txt_title=[]\n",
    "\n",
    "pages = np.arange(2,500)\n",
    "\n",
    "get_laws_p1('https://eur-lex.europa.eu/search.html?SUBDOM_INIT=ALL_ALL&DTS_DOM=ALL&type=advanced&DTS_SUBDOM=ALL_ALL&excConsLeg=true&qid=1607349508496&locale=en#')\n",
    "\n",
    "for page in pages:\n",
    "    page_extract = requests.get(\"\"\"https://eur-lex.europa.eu/search.html?SUBDOM_INIT=ALL_ALL&DTS_DOM=ALL&type=advanced&DTS_SUBDOM=ALL_ALL&excConsLeg=true&qid=1607349508496&locale=en&page=\"\"\"+str(page))\n",
    "    soup = BeautifulSoup(page_extract.text, 'html.parser')\n",
    "    urls = list(soup.find_all('h2'))\n",
    "    \n",
    "    for url in urls:\n",
    "        txt1.append(re.findall('https://?[\\w/\\-?=%.]+\\.[\\w/\\-?=%.:\\d]+', str(url)))\n",
    "    \n",
    "    for title in urls:\n",
    "        titles.append(re.findall('>\\w+.+<',str(title)))\n",
    "\n",
    "for line in titles:\n",
    "    for el in line:\n",
    "        txt_title.append(re.sub('[><]|/a','',el))\n",
    "\n",
    "document_list= pd.DataFrame({\n",
    "    'Titles': txt_title,\n",
    "    'URL': txt1})\n",
    "\n",
    "document_list.drop(document_list.loc[(document_list.Titles == 'Search criteria') | (document_list.URL == \"\"\"[]\"\"\")].index, inplace = True)\n",
    "    \n",
    "document_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CleaningDataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'extracted_laws' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-527-8b78eab29a53>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdocument_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextracted_laws\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'extracted_laws' is not defined"
     ]
    }
   ],
   "source": [
    "document_list.to_csv(\"extracted_laws.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
